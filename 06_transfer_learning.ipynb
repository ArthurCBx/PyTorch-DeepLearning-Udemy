{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArthurCBx/PyTorch-DeepLearning-Udemy/blob/main/06_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtlfXHBM6SVj"
      },
      "source": [
        "# 06. PyTorch Transfer Learning\n",
        "\n",
        "What is transfer learning?\n",
        "\n",
        "Transfer learning involver taking the parameters of what one model has learned on another dataset and applying to our own problem.\n",
        "\n",
        "* Pretrained model = foundation models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj9dwlHz4iKr"
      },
      "source": [
        "Where to find pre-trained models:\n",
        "* PyTorch documentation\n",
        "* Torch iamge Models (timm library)\n",
        "* HuggingFace Hub\n",
        "* Paperswithcode SOTA(State of the arte)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugefC1b76-BD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAC-_JX5Ltpp"
      },
      "source": [
        "Now we've got the versions of torch and torchvision, we're after, let's import the code we've written in previous sections so that we don't have to write it all again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CrIaq64MGY4"
      },
      "outputs": [],
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hz5tWSgTNHEh"
      },
      "outputs": [],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH0VIow1OOpg"
      },
      "source": [
        "## 1. Get data\n",
        "\n",
        "We need our pizza, steak, sushi data to build a transfer learning model on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "699eqO4yOGBT"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/mrdbourke/pytorch-deep-learning/raw/refs/heads/main/data/pizza_steak_sushi.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-I7TohPPKuF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory exists, skipping re-download.\")\n",
        "else:\n",
        "  print(f\"Did not find {image_path} directory, downloading it...\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "    print(\"Downloading, pizza, steak, sushi data...\")\n",
        "    f.write(request.content)\n",
        "\n",
        "  with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping pizza, steak, sushi data...\")\n",
        "    zip_ref.extractall(image_path)\n",
        "\n",
        "  os.remove(data_path / \"pizza_steak_sushi.zip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpFHOaucQszv"
      },
      "outputs": [],
      "source": [
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMTp_UVpReWI"
      },
      "source": [
        "## 2. Create Datasets and DataLoaders\n",
        "\n",
        "Now we've got some data, want to turn it into PyTorch DataLoaders.\n",
        "\n",
        "To do so, we can use `data_setup.py` and the `create_dataloaders()` function we made in 05.\n",
        "\n",
        "There's one thing we have to think about when loading: how to **transform** it?\n",
        "\n",
        "And with `torchvision` 0.13+ there's two ways to do this:\n",
        "\n",
        "1. Manually created transforms - you define what transforms you want your data to go through.\n",
        "2. Automatically created transforms - the transforms for your data are defined by the model you'd like to use.\n",
        "\n",
        "Important point: when using a pretrained model, it's important that the data (including your custom data) that you pass through it is **transformed** in the same way that the data the model was trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bjMc5oWTQtK"
      },
      "source": [
        "### 2.1 Creating a transform for `torchvision.models` (manual creation)\n",
        "\n",
        "`torchvision.models` contains pretrained models (models ready for transfer learning) right within `torchvision`.\n",
        "\n",
        "> All pre-trained models expect input images normalized in the same way i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0,1] and then normalized with the models parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k_dsroNUWqR"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzgdg_CMRQJu"
      },
      "outputs": [],
      "source": [
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    transform=manual_transforms,\n",
        "    batch_size=32\n",
        "    )\n",
        "\n",
        "train_dataloader,test_dataloader, class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULIs7HN7eTqL"
      },
      "source": [
        "### 2.2 Creating a transform for `torchvision.models` (auto creation)\n",
        "\n",
        "As of `torchvision` v0.13+ there is now support for automatic data transform creation based on the pretrained model weights you're using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMYS_khkekvz"
      },
      "outputs": [],
      "source": [
        "# Get a set of pretrained model weights\n",
        "\n",
        "weights = torchvision.models.EfficientNet_V2_S_Weights.DEFAULT # \"DEFAULT\" = best available weights\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCs5J2_1gWqG"
      },
      "outputs": [],
      "source": [
        "# Get the transforms used to create our pretrained weights\n",
        "\n",
        "auto_transforms = weights.transforms()\n",
        "auto_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HazGLO0heAt"
      },
      "outputs": [],
      "source": [
        "# Create DataLoaders using automatic transforms\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=auto_transforms,\n",
        "                                                                               batch_size=32)\n",
        "\n",
        "train_dataloader,test_dataloader, class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GurkYzNxicMg"
      },
      "source": [
        "## 3. Getting a pretrained model\n",
        "\n",
        "There are various places to get a pretrained model, such as:\n",
        "1. PyTorch domain libraries\n",
        "2. Libraries like `timm` (torch image models)\n",
        "3. HuggingFace Hub (for plenty of different models)\n",
        "4. Paperswithcode (for models across different problem spaces/domains)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UBuA861iyAE"
      },
      "source": [
        "### 3.1 Which pretrained model should you use?\n",
        "\n",
        "*Experiment,Experiment,Experiment*\n",
        "\n",
        "The whole idea of transfer learning: take an already well-performing model from a problem space similar to your own and then customize to your own problem.\n",
        "\n",
        "Three thing to consider:\n",
        "1. Speed - how fast does it run?\n",
        "2. Size - how big is the model?\n",
        "3. Performance - how well does it go on your chosen problem (e.g. how well does it classify food images?)\n",
        "\n",
        "Where does the model live?\n",
        "\n",
        "Is it on device (like a self-driving car) or does it live on a server?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF2TeH2RnASg"
      },
      "source": [
        "### 3.2 Setting up a pretrained model\n",
        "\n",
        "Want to create an instance of a pretrained EfficientNet_V2_S"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZeNFeCHixWp"
      },
      "outputs": [],
      "source": [
        "# Old method of creating a pretrained model (prior to torchvision v0.13)\n",
        "#model = torchvision.models.efficientnet_v2_s(pretrained=True)\n",
        "\n",
        "# New method of creating a pretrained model\n",
        "weights = torchvision.models.EfficientNet_V2_S_Weights.DEFAULT\n",
        "model = torchvision.models.efficientnet_v2_s(weights=weights)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm5M33GIobYb"
      },
      "outputs": [],
      "source": [
        "model.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KLvy7ibonmk"
      },
      "outputs": [],
      "source": [
        "model.classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlA2VCRF81jc"
      },
      "source": [
        "### 3.3 Getting a summary of our model with `torchinfo.summary()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPlOJyTW89zk"
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary\n",
        "summary(model=model,\n",
        "        input_size=(1,3,224,224),\n",
        "        col_names=[\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZSoCYaAv7kh"
      },
      "source": [
        "### 3.4 Freezing the base model and changing the output layer to suit our needs\n",
        "\n",
        "With a feature extractor model, typically you will \"freeze\" the base layers of a pretrained/foundation model and update the output layers to suit your own problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dtkh_GMov7II"
      },
      "outputs": [],
      "source": [
        "# Freeze all of the base layers\n",
        "for param in model.features.parameters():\n",
        "  param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObXkVvrTyhta"
      },
      "outputs": [],
      "source": [
        "# Update the classifier head of our model to suit our problem\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "model = model.to(device)\n",
        "\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.2,inplace=True),\n",
        "    nn.Linear(in_features=1280,\n",
        "              out_features=len(class_names))\n",
        ")\n",
        "model.classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpp-Z5By2GpP"
      },
      "source": [
        "## 4. Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9fYAmgI0IXZ"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aus9HlZu2iXX"
      },
      "outputs": [],
      "source": [
        "# Import train function\n",
        "from going_modular.going_modular import engine\n",
        "\n",
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Setup training and save the results\n",
        "results = engine.train(model=model,\n",
        "                       train_dataloader=train_dataloader,\n",
        "                       test_dataloader=test_dataloader,\n",
        "                       optimizer=optimizer,\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=10,\n",
        "                       device=device)\n",
        "\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO6ULgwt4Ss1"
      },
      "source": [
        "## 5. Evaluate model by plotting loss curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xx8qPT253kv3"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  from helper_functions import plot_loss_curves\n",
        "except:\n",
        "  print(f\"[INFO] Couldn't find helper_functions.py, downloading it...\")\n",
        "  with open(\"helper_functions.py\",\"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/helper_functions.py\")\n",
        "    print(\"Downloading helper_functions.py...\")\n",
        "    f.write(request.content)\n",
        "  from helper_functions import plot_loss_curves\n",
        "\n",
        "# Plot the loss curves of our model\n",
        "plot_loss_curves(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGlZNHStLXLp"
      },
      "source": [
        "## 6. Make predictions on images from the test set\n",
        "\n",
        "Let's add here to the data explorer's motto of *visualize,visualize,visualize*!\n",
        "\n",
        "And make some qualitative predictions on our test set.\n",
        "\n",
        "Some things to keep in mind when making predictions/inference on test data/custom data.\n",
        "\n",
        "We have to make sure that our test/custom data is:\n",
        "* Same shape - images need to be same shape as model was trained on\n",
        "* Same datatype - custom data should be in the same data type\n",
        "* Same device - custom test data should be in the same device as the model\n",
        "* Same transform - if you've transformed your custom data, ideally you will transform the test data and custom data the same\n",
        "\n",
        "To do all of this automatically, let's create a function called `pred_and_plot_image()`:\n",
        "1. Take in a trained model, a list of class names, a filepath to a target image, an image size, a transform and a target device\n",
        "2. Open the image with `PIL.Image.Open()`\n",
        "3. Create a transform if one doesn't exist\n",
        "4. Make sure the model is on the target device\n",
        "5. Turn the model to `model.eval()` mode to make sure it's ready for inference (this will turn off things like `nn.Dropout()`)\n",
        "6. Transform the target image and make sure its dimensionality is suited for the model (this mainly relates to batch size)\n",
        "7. Make a prediction on the image by passing to the model\n",
        "8. Plot the image with `matplotlib` and set the title to the prediction label and prediction probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_ULQh0qLWqT"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "# 1. Take in a trained model\n",
        "\n",
        "def pred_and_plot_image(model: torch.nn.Module,\n",
        "                        image_path: str,\n",
        "                        class_names: List[str],\n",
        "                        image_size: Tuple[int,int]=(224,224),\n",
        "                        transform: torchvision.transforms = None,\n",
        "                        device: torch.device = device):\n",
        "\n",
        "  # 2. Open the image with PIL\n",
        "  img = Image.open(image_path)\n",
        "\n",
        "  # 3. Create a transform if one doesn't exist\n",
        "  if transform is not None:\n",
        "    image_transform = transform\n",
        "  else:\n",
        "    image_transform = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        transfroms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "  ### Predict on image ###\n",
        "  # 4. Make sure the model is on target device\n",
        "  model.to(device)\n",
        "\n",
        "  # 5. Turn on inference and eval mode\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    # 6. Transform the image and add an extra batch dimension\n",
        "    transformed_image = image_transform(img).unsqueeze(dim=0)\n",
        "\n",
        "    # 7. Make a prediction on the transformed image by passing it to the model\n",
        "    target_image_pred = model(transformed_image.to(device))\n",
        "\n",
        "  target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
        "\n",
        "  target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
        "\n",
        "  # 8. Plot image with predicted label and probability\n",
        "  plt.figure()\n",
        "  plt.imshow(img)\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(f\"Pred: {class_names[target_image_pred_label]} | Prob: {target_image_pred_probs.max():.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random list of image paths from the test set\n",
        "import random\n",
        "\n",
        "num_images_to_plot = 3\n",
        "test_image_path_list = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "test_image_path_sample = random.sample(population=test_image_path_list,\n",
        "                                       k=num_images_to_plot)\n",
        "for image_path in test_image_path_sample:\n",
        "  pred_and_plot_image(model=model,\n",
        "                      image_path=image_path,\n",
        "                      class_names=class_names,\n",
        "                      transform=auto_transforms,\n",
        "                      device=device)"
      ],
      "metadata": {
        "id": "wt2WuAvFI8n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Making predictions on a custom image"
      ],
      "metadata": {
        "id": "CAcf5fGUMGjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "custom_image_path = data_path / \"04-pizza-dad.jpeg\"\n",
        "\n",
        "if not custom_image_path.is_file():\n",
        "  with open(custom_image_path, \"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/04-pizza-dad.jpeg\")\n",
        "    print(\"Downloading custom image...\")\n",
        "    f.write(request.content)\n",
        "else:\n",
        "  print(f\"{custom_image_path} already exists\")"
      ],
      "metadata": {
        "id": "a5Tz6dTYL6pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_plot_image(model=model,\n",
        "                      image_path=custom_image_path,\n",
        "                      class_names=class_names,\n",
        "                      transform=auto_transforms,\n",
        "                      device=device)"
      ],
      "metadata": {
        "id": "U-dP-l50MwcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercises\n"
      ],
      "metadata": {
        "id": "NG60P6uORV_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Make predictions on the entire test dataset and plot a confusion matrix for the results of our model compared to the truth labels."
      ],
      "metadata": {
        "id": "yJ0vRn9rRXqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics"
      ],
      "metadata": {
        "id": "Ha1zTrKnRebq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "confmat = ConfusionMatrix(task=\"MULTICLASS\",num_classes=len(class_names))\n",
        "\n",
        "predictions_label = []\n",
        "\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  for batch, (X,y) in enumerate(test_dataloader):\n",
        "    X,y = X.to(device), y.to(device)\n",
        "    y_pred = model(X)\n",
        "    y_pred_label = torch.argmax(torch.softmax(y_pred,dim=1),dim=1)\n",
        "    predictions_label.append(y_pred_label.cpu())\n",
        "\n",
        "y_pred_tensor = torch.cat(predictions_label)\n",
        "target_tensor = torch.cat([y for X,y in test_dataloader])\n",
        "\n",
        "confmat_tensor = confmat(y_pred_tensor,target=target_tensor)\n",
        "fig, ax = plot_confusion_matrix(conf_mat=confmat_tensor.numpy(),\n",
        "                                  figsize=(10,10),\n",
        "                                  colorbar=True,\n",
        "                                  class_names=class_names)\n"
      ],
      "metadata": {
        "id": "fJmVGW75SbEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Get the \"most wrong\" of the predictions on the test dataset and plot the 5 \"most wrong\" images. You can do this by:\n",
        "* Predicting across all of the test dataset, storing the labels and predicted probabilities.\n",
        "* Sort the predictions by wrong prediction and then descending predicted probabilities, this will give you the wrong predictions with the highest prediction probabilities, in other words, the \"most wrong\".\n",
        "* Plot the top 5 \"most wrong\" images, why do you think the model got these wrong?"
      ],
      "metadata": {
        "id": "nDNuRShAgy-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Get all test data paths\n",
        "test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "test_labels = [path.parent.stem for path in test_data_paths]\n",
        "\n",
        "# Create a function to return a list of dictionaries with sample,label, pred_prob\n",
        "\n",
        "def pred_and_store(test_paths, model, transform,class_names):\n",
        "  test_pred_list = []\n",
        "  for path in test_paths:\n",
        "    pred_dict = {}\n",
        "\n",
        "    pred_dict[\"image_path\"] = path\n",
        "    class_name = path.parent.stem\n",
        "    pred_dict[\"class_name\"] = class_name\n",
        "\n",
        "    from PIL import Image\n",
        "    img = Image.open(path)\n",
        "    transformed_image = transform(img).unsqueeze(0) # Add batch dimension\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "      pred_prob = torch.softmax(model(transformed_image.to(device)),dim=1)\n",
        "      pred_label = torch.argmax(pred_prob,dim=1)\n",
        "      pred_class = class_names[pred_label.cpu()]\n",
        "\n",
        "      pred_dict[\"pred_prob\"] = pred_prob.unsqueeze(0).max().cpu().item()\n",
        "      pred_dict[\"pred_class\"] = pred_class\n",
        "\n",
        "    pred_dict[\"correct\"] = pred_class == class_name\n",
        "\n",
        "    test_pred_list.append(pred_dict)\n",
        "\n",
        "  return test_pred_list\n",
        "\n",
        "pred_list = pred_and_store(test_paths=test_data_paths,model=model,transform=auto_transforms,class_names=class_names)"
      ],
      "metadata": {
        "id": "CtRp51quW4-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_list"
      ],
      "metadata": {
        "id": "SqQv5LBBlfY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_pred_df = pd.DataFrame(pred_list)\n",
        "top_5_most_wrong = test_pred_df.sort_values(by=[\"correct\",\"pred_prob\"],ascending=[True,False]).head()\n",
        "top_5_most_wrong\n"
      ],
      "metadata": {
        "id": "1wmPS_ArnivQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "for row in top_5_most_wrong.iterrows():\n",
        "  row=row[1]\n",
        "  image_path = row[0]\n",
        "  true_label=row[1]\n",
        "  pred_prob = row[2]\n",
        "  pred_class = row[3]\n",
        "  img = torchvision.io.read_image(str(image_path))\n",
        "  plt.figure()\n",
        "  plt.imshow(img.permute(1,2,0))\n",
        "  plt.title(f\"True: {true_label} | Pred: {pred_class} | Prob: {pred_prob:.3f}\")\n",
        "  plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "lnuFgDRKo0B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Train the model from section 4 above for longer (10 epochs should do), what happens to the performance?"
      ],
      "metadata": {
        "id": "v1W7xzpm7Hch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With more epochs the model accuracy increased, even more in the testing data in comparison with the training data, so there's no overfitting yet"
      ],
      "metadata": {
        "id": "KeKyiSE27sSQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Train the model from section 4 above with more data, say 20% of the images from Food101 of Pizza, Steak and Sushi images."
      ],
      "metadata": {
        "id": "e-604y-U8bVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "bigger_data_path = Path(\"bigger_data\")\n",
        "bigger_data_dir = bigger_data_path / \"pizza_steak_sushi_20_percent\"\n",
        "\n",
        "if bigger_data_dir.is_dir():\n",
        "  print(f\"{bigger_data_path} directory already exists\")\n",
        "else:\n",
        "  print(f\"Creating {bigger_data_path} directory\")\n",
        "  bigger_data_dir.mkdir(parents=True,exist_ok=True)\n",
        "\n",
        "with open(bigger_data_path / \"pizza_steak_sushi_20_percent.zip\",\"wb\") as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\")\n",
        "  f.write(request.content)\n",
        "\n",
        "with zipfile.ZipFile(bigger_data_path / \"pizza_steak_sushi_20_percent.zip\",\"r\") as zip_ref:\n",
        "  print(\"Unzipping pizza_steak_sushi_20_percent.zip...\")\n",
        "  zip_ref.extractall(bigger_data_path)\n",
        "  os.remove(bigger_data_path / \"pizza_steak_sushi_20_percent.zip\")\n",
        "\n",
        "train_dir = bigger_data_path / \"train\"\n",
        "test_dir = bigger_data_path / \"test\""
      ],
      "metadata": {
        "id": "wT2P4dOL8fPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.EfficientNet_V2_M_Weights.DEFAULT\n",
        "model = torchvision.models.efficientnet_v2_m(weights=weights)\n",
        "transformation = weights.transforms()"
      ],
      "metadata": {
        "id": "0BP70O_n_4x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=transformation,\n",
        "                                                                               batch_size=32,\n",
        "                                                                               num_workers=os.cpu_count(),\n",
        "                                                                               )"
      ],
      "metadata": {
        "id": "efKJNrKj-82Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.features.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.2,inplace=True),\n",
        "    nn.Linear(in_features=1280,out_features=3)\n",
        ")"
      ],
      "metadata": {
        "id": "kDHbM48YBbJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "fFOtLbiiCv5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import engine\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "results = engine.train(model=model,\n",
        "                       train_dataloader=train_dataloader,\n",
        "                       test_dataloader=test_dataloader,\n",
        "                       optimizer=optimizer,\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=10,\n",
        "                       device=device)\n",
        "\n"
      ],
      "metadata": {
        "id": "I1k63iksCDRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confmat = ConfusionMatrix(task=\"MULTICLASS\",num_classes=len(class_names))\n",
        "\n",
        "predictions_label = []\n",
        "\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  for batch, (X,y) in enumerate(test_dataloader):\n",
        "    X,y = X.to(device), y.to(device)\n",
        "    y_pred = model(X)\n",
        "    y_pred_label = torch.argmax(torch.softmax(y_pred,dim=1),dim=1)\n",
        "    predictions_label.append(y_pred_label.cpu())\n",
        "\n",
        "y_pred_tensor = torch.cat(predictions_label)\n",
        "target_tensor = torch.cat([y for X,y in test_dataloader])\n",
        "\n",
        "confmat_tensor = confmat(y_pred_tensor,target=target_tensor)\n",
        "fig, ax = plot_confusion_matrix(conf_mat=confmat_tensor.numpy(),\n",
        "                                  figsize=(10,10),\n",
        "                                  colorbar=True,\n",
        "                                  class_names=class_names)"
      ],
      "metadata": {
        "id": "QLNrk-XREgWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pathlist = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "\n",
        "pred_and_plot_image(model=model,\n",
        "                    image_path=random.choice(pathlist),\n",
        "                    transform=transformation,\n",
        "                    device=device,\n",
        "                    class_names=class_names)"
      ],
      "metadata": {
        "id": "1xdeG_usErIp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyM2Y5bEWmkfCzpN9hYQYwBT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}